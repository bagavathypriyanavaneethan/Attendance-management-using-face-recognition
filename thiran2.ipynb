

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()

## ---(Wed Oct  2 22:17:36 2019)---
"""
Created on Wed Oct  2 22:18:17 2019

@author: DELL
"""

import cv2 
import os 
import numpy as np 
from random import shuffle 
from tqdm import tqdm
"""
Created on Wed Oct  2 22:18:17 2019

@author: DELL
"""

import cv2 
import os 
import numpy as np 
from random import shuffle 
from tqdm import tqdm 

TRAIN_DIR = r'D:\dataset1\face1\train1'
TEST_DIR = r'D:\dataset1\face1\test1'
IMG_SIZE = 50
LR = 1e-3
print(len(os.listdir(TRAIN_DIR)))
print(len(os.listdir(TRAIN_DIR)))
print(len(os.listdir(TEST_DIR)))
MODEL_NAME = 'face.model'.format(LR, '6conv-basic')
def label_img(img): 
    word_label = img.split('.')[-5] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1]
def label_img(img): 
    word_label = img.split('.')[-5] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1] 


def create_train_data(): 
    # Creating an empty list where we should store the training data 
    # after a little preprocessing of the data 
    training_data = [] 
    
    # tqdm is only used for interactive loading 
    # loading the training data 
    for img in tqdm(os.listdir(TRAIN_DIR)): 
        
        # labeling the images 
        label = label_img(img) 
        
        path = os.path.join(TRAIN_DIR, img) 
        
        # loading the image from the path and then converting them into 
        # greyscale for easier covnet prob 
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) 
        
        # resizing the image for processing them in the covnet 
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) 
        
        # final step-forming the training data list with numpy array of the images 
        training_data.append([np.array(img), np.array(label)]) 
    
    # shuffling of the training data to preserve the random state of our data 
    shuffle(training_data) 
    
    # saving our trained data for further uses if required 
    np.save('train_data.npy', training_data) 
    return training_data
def process_test_data(): 
    testing_data = [] 
    for img in tqdm(os.listdir(TEST_DIR)): 
        path = os.path.join(TEST_DIR, img) 
        img_num = img.split('.')[0] 
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) 
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) 
        testing_data.append([np.array(img), img_num]) 
    
    shuffle(testing_data) 
    np.save('test_data.npy', testing_data) 
    return testing_data
train_data = create_train_data() 
test_data = process_test_data()
def label_img(img): 
    word_label = img.split('.')[5] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1]
train_data = create_train_data() 
test_data = process_test_data()

## ---(Fri Oct  4 13:11:14 2019)---
import cv2 
import os 
import numpy as np 
from random import shuffle 
from tqdm import tqdm
TRAIN_DIR = r'D:\dataset1\face1\train1'
TEST_DIR = r'D:\dataset1\face1\test1'
IMG_SIZE = 50
LR = 1e-3
print(len(os.listdir(TRAIN_DIR)))
print(len(os.listdir(TEST_DIR)))
MODEL_NAME = 'face.model'.format(LR, '6conv-basic')
def label_img(img): 
    word_label = img.split('.')[5] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1]
def create_train_data(): 
    # Creating an empty list where we should store the training data 
    # after a little preprocessing of the data 
    training_data = [] 
    
    # tqdm is only used for interactive loading 
    # loading the training data 
    for img in tqdm(os.listdir(TRAIN_DIR)): 
        
        # labeling the images 
        label = label_img(img) 
        
        path = os.path.join(TRAIN_DIR, img) 
        
        # loading the image from the path and then converting them into 
        # greyscale for easier covnet prob 
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) 
        
        # resizing the image for processing them in the covnet 
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) 
        
        # final step-forming the training data list with numpy array of the images 
        training_data.append([np.array(img), np.array(label)]) 
    
    # shuffling of the training data to preserve the random state of our data 
    shuffle(training_data) 
    
    # saving our trained data for further uses if required 
    np.save('train_data.npy', training_data) 
    return training_data
def process_test_data(): 
    testing_data = [] 
    for img in tqdm(os.listdir(TEST_DIR)): 
        path = os.path.join(TEST_DIR, img) 
        img_num = img.split('.')[0] 
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) 
        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) 
        testing_data.append([np.array(img), img_num]) 
    
    shuffle(testing_data) 
    np.save('test_data.npy', testing_data) 
    return testing_data
train_data = create_train_data() 
test_data = process_test_data()
def label_img(img): 
    word_label = img.split('.')[4] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1]
train_data = create_train_data() 
test_data = process_test_data()
def label_img(img): 
    word_label = img.split('.')[-5] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1]
train_data = create_train_data() 
test_data = process_test_data()
def label_img(img): 
    word_label = img.split('.')[-4] 
    # DIY One hot encoder 
    if word_label == 'baggu': return [1, 0] 
    elif word_label == 'fathi': return [0, 1]
train_data = create_train_data() 
test_data = process_test_data()